{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reanalysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Additional clarifying information was provided by the Behaviorally team.\n",
    "While they had previously identified a set of products as the level of analysis; what they meant was the subset of UPC's associated with those products (I don't know what they are using 'UPC' for, but it's certainly not the common usage of [\"Universal Product Code\"](https://www.barcode-us.info/upc-codes/]).\n",
    "Nisha mentioned that the UPCs in the data correspond to individual images of interest; which is truly the correct level of analysis.\n",
    "They are interested _only_ in the UPCs that were actually run, which makes sense.\n",
    "The problem is just that they didn't identify these initially; but these images-of-interest will be a further subset of upcs associated with the products in the set previous identified.\n",
    "\n",
    "From the debrief in [analysis.ipynb](notebooks/analysis.ipynb):\n",
    "\n",
    "> It turns out there are only 51 images of interest to Behaviorally.\n",
    "> This changes the analysis substantially.\n",
    "> Choosing to see this as something positive; narrowing things down this much allows us to really focus in on things.\n",
    ">\n",
    "> Starting with narrowing the predicted ONS values Tony had set up, this presents a much more focused approach to the rest of the data, and will make it much easier to drill down into specifics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory\n",
    "\n",
    "This just helps with using local imports from the larger project to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrismessier/work/behaviorally\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy import random as rng\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_pb2, status_code_pb2\n",
    "\n",
    "import processors\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for replicability\n",
    "rng.seed(42)\n",
    "# rng.seed(304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "sns.set(\n",
    "    style='darkgrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import KEY_METRICS,\\\n",
    "    KEY_CONDITIONALS,\\\n",
    "    TO_NORMALIZE,\\\n",
    "    ONS_ANALYSIS_JOB_NUMBERS  # Job Numbers of interest for this\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 51  # sample size for images, keep LOW for dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(data, x, y, title=None, period_length=13):\n",
    "    g = sns.lineplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue='Image ID', # hue='Brand Name', # hue=\"Image Name\",  # hue=\"Product\",\n",
    "        data=data,\n",
    "        legend=True\n",
    "    )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlim((0,156))  # for the items not just in single periods\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    g.set_xticks(range(data['report_dates'].nunique())) # <--- set the ticks first\n",
    "    g.set_xticklabels([t.strftime('%b %d, %Y') for t in data['report_dates'].unique()])\n",
    "\n",
    "    for i, label in enumerate(g.xaxis.get_ticklabels()):\n",
    "        if ((i+1) % period_length) == 0:\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have all of the information that I need for this analysis, I can finally string things together in a sensible manner; cleaning up was I had initially done in the [project-forensics.ipynb](./project-forensics.ipynb) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANED_DATA = \"/Users/chrismessier/work/behaviorally/data/behaviorally_merged_sales_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (55848, 22)\n",
      "df shape: (35906, 22)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CLEANED_DATA, index_col=0)\n",
    "print(f\"df shape:\", df.shape)\n",
    "df = df.infer_objects()\n",
    "df.dropna(inplace=True)\n",
    "print(f\"df shape:\", df.shape)\n",
    "df['REPORT'] = pd.Categorical(df['REPORT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Image ID</th>\n",
       "      <th>Raw ONS Line and Pack</th>\n",
       "      <th>job_number</th>\n",
       "      <th>upc</th>\n",
       "      <th>upc_10</th>\n",
       "      <th>UPC 10 digit</th>\n",
       "      <th>Product</th>\n",
       "      <th>Dollar Sales</th>\n",
       "      <th>Dollar Sales % Change vs YA</th>\n",
       "      <th>...</th>\n",
       "      <th>Unit Share of Category</th>\n",
       "      <th>Unit Share of Category Year Ago</th>\n",
       "      <th>Unit Share of SubCategory</th>\n",
       "      <th>Unit Share of SubCategory Year Ago</th>\n",
       "      <th>Price per Unit</th>\n",
       "      <th>Price per Unit % Change vs YA</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Sub-Category Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>REPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AB474_LINE15.jpg</td>\n",
       "      <td>LINE15</td>\n",
       "      <td>89.0</td>\n",
       "      <td>AB474</td>\n",
       "      <td>20735110225</td>\n",
       "      <td>2.073511e+09</td>\n",
       "      <td>2.073511e+09</td>\n",
       "      <td>TURKEY HILL FROZEN COOKIE AND CREAM ICE CREAM ...</td>\n",
       "      <td>260221.616285</td>\n",
       "      <td>0.00616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214314</td>\n",
       "      <td>0.166309</td>\n",
       "      <td>0.245011</td>\n",
       "      <td>0.189175</td>\n",
       "      <td>2.97168</td>\n",
       "      <td>-0.160924</td>\n",
       "      <td>ICE CREAM/SHERBET</td>\n",
       "      <td>ICE CREAM</td>\n",
       "      <td>TURKEY HILL</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image Name Image ID  Raw ONS Line and Pack job_number          upc  \\\n",
       "46  AB474_LINE15.jpg   LINE15                   89.0      AB474  20735110225   \n",
       "\n",
       "          upc_10  UPC 10 digit  \\\n",
       "46  2.073511e+09  2.073511e+09   \n",
       "\n",
       "                                              Product   Dollar Sales  \\\n",
       "46  TURKEY HILL FROZEN COOKIE AND CREAM ICE CREAM ...  260221.616285   \n",
       "\n",
       "    Dollar Sales % Change vs YA  ...  Unit Share of Category  \\\n",
       "46                      0.00616  ...                0.214314   \n",
       "\n",
       "    Unit Share of Category Year Ago  Unit Share of SubCategory  \\\n",
       "46                         0.166309                   0.245011   \n",
       "\n",
       "    Unit Share of SubCategory Year Ago  Price per Unit  \\\n",
       "46                            0.189175         2.97168   \n",
       "\n",
       "    Price per Unit % Change vs YA      Category Name  Sub-Category Name  \\\n",
       "46                      -0.160924  ICE CREAM/SHERBET          ICE CREAM   \n",
       "\n",
       "     Brand Name REPORT  \n",
       "46  TURKEY HILL  128.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE moved to tools.infer_report_dates\n",
    "# from itertools import count\n",
    "\n",
    "# T = 156  # total number of reports\n",
    "\n",
    "# START_DATE = '3/31/2019'  # just from looking at the Index page from their report spreadsheet.\n",
    "\n",
    "# report_dates = {}\n",
    "# t_0 = pd.to_datetime(START_DATE)  # just from looking at the Index page from their report spreadsheet.\n",
    "# for i in count(start=1):\n",
    "#     t_i = t_0 + pd.Timedelta(i, unit='w')  # period t_i\n",
    "#     report_dates[float(i)] = t_i\n",
    "#     if i-1 == T:\n",
    "#         break\n",
    "\n",
    "# df['report_dates'] = df['REPORT'].apply(lambda x: report_dates.get(x))\n",
    "# df['report_dates'] = pd.to_datetime(df['report_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'REPORT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'REPORT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/lm_7rf3d5ps61msgmysz6bjr0000gn/T/ipykernel_64735/1286845309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 'REPORT' is the ndx column for the timeseries, or \"report number\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'report_dates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_report_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'REPORT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/behaviorally/tools/__init__.py\u001b[0m in \u001b[0;36minfer_report_dates\u001b[0;34m(data, target_column, periods, frequency, start_date)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0minfered_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreport_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0minfered_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfered_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/v1/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'REPORT'"
     ]
    }
   ],
   "source": [
    "# 'REPORT' is the ndx column for the timeseries, or \"report number\"\n",
    "df['report_dates'] = tools.infer_report_dates(df['REPORT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I said in the debrief, changing things to this _greatly_ narrowed set of images makes for a lot more value in looking at things at the level of an individual product image; because we simultaneously have narrowed the products-of-interest down to the aforementioned 51 but we have also narrowed the scope of our analysis down to just one of the 5-ish images that we have for each product, so we can avoid the headaches of the widely-varying One Number Score (ONS) values between different images of the same product.\n",
    "All of this makes looking at individual results so much easier.\n",
    "I think something that could be useful is showing the lifecycle of products across periods.\n",
    "Let me take a look at that now!\n",
    "\n",
    "As we are still waiting on the update from Nisha on the specific images of interest, I'll simply sample an item at random and look at it across all of the \"Periods\".\n",
    "This means looking at a random `'upc'` value, because this will be the base identifying unit for the data.\n",
    "\n",
    "WRONG!!!\n",
    "\n",
    "After going through this once, right now in the prepared data there is a many-to-one correspondence between `'Image Name'` and `'upc'`; but from what @nisha has been reporting, it should be a one-to-one correspondence.\n",
    "So I'm just going to switch to looking at the `'Image Name'`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, they're only interested in the `LINE` Images, so, let's narrow it down to that and get our random image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm assuming that this is going to be exclusively 'LINE' or 'PACK'; therefore `line` can be treated as binary\n",
    "for i, row in df.iterrows():\n",
    "    image_id = row['Image ID']\n",
    "    pack = True  \n",
    "    if 'LINE' in image_id:\n",
    "        pack = False\n",
    "    elif 'PACK' in image_id:\n",
    "        # the 'other' condition\n",
    "        continue\n",
    "    else:\n",
    "        # this however, would be unexpected...\n",
    "        print(image_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Image ID'].apply(lambda idx: 'LINE' in idx.upper())].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to a random image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight change, so I am taking another pass. I am going to look at a set of images, so that I can then just pass in the images of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.choice(df['Image Name'].unique(), size=(N,))\n",
    "print(f\"Our random images are: {X}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[df['Image Name'].isin(X)].copy()\n",
    "print(f\"{df_.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df_[['Image Name'] + TO_NORMALIZE].copy()\n",
    "df_norm = df_norm.groupby('Image Name').transform(lambda x: (x - x.mean()) / x.std())\n",
    "df_norm.dropna(axis=1, inplace=True)\n",
    "print(df_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the normalized figures\n",
    "\n",
    "norm_column_format = lambda c: '_'.join([s.lower() for s in c.split()] + ['norm'])\n",
    "\n",
    "for i, row in df_norm.iterrows():\n",
    "    for j, v in row.items():\n",
    "        j_ = norm_column_format(j)\n",
    "        # print(i, j_, v)\n",
    "        df_.loc[i, j_] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = \"REPORT\"\n",
    "\n",
    "for y in df_.columns:\n",
    "    if '_norm' in y:\n",
    "        plot_series(df_, x_val, y, y);\n",
    "\n",
    "for y in KEY_METRICS:\n",
    "    plot_series(df_, x_val, y, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['Brand Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!\n",
    "This _does_ map to one observation from each of the 156 periods.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Was this image _not_ shown in period $t_{-1}$?\n",
    "That would be one way to gauge impact.\n",
    "\n",
    "Perahps this was just one of the items where there _wasn't_ a change to packaging or marketing material over the course of 3 years, but that seems odd; so I'm going to resample a few times to confirm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ = rng.choice(df_['upc'].unique())\n",
    "# print(f\"Our random upc is: {x_}!\")\n",
    "\n",
    "# df_ = df_[df_['upc'] == x_].copy()\n",
    "# print(f\"{df_.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert df_['Product'].nunique() == 1, 'check'\n",
    "# name = df_['Product'].values[0]\n",
    "\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the smaller set, it might be worth the time to come up with more readible product names.\n",
    "PArticularly if there aren't, say, more than one type of 'Gold Bond', or if they are, hopefully they can be differentiated by sizes, i.e. 'Gold Bond - 4oz', 'Gold Bond - 8oz', 'Gold Bond - 16oz' (I have no idea how accurate these are...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Raw ONS Line and Pack'\n",
    "y = 'Dollar Sales'\n",
    "\n",
    "df_[x].corr(df[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, *_ = KEY_METRICS\n",
    "periods = df_['REPORT'].values \n",
    "\n",
    "for y in KEY_METRICS:  # NOTE i was trying to just look at the $Y$-values, but the $x$-value as well.\n",
    "    if y == x:\n",
    "        print(\"skipping\", x)\n",
    "        continue\n",
    "    \n",
    "    plot_series(df_, 'REPORT', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Very_ high degree of intercorrelation between these series; however, they do differ somewhat.\n",
    "Look at the values between $t_{r}$ and  $t_{s}$ on the plot above. <ephemeral>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think there's use in looking at this for each single product.\n",
    "Demonstrate the peiodicity, seasonality, underlying trends, etc.\n",
    "They may honestly just need someone to do that basic timeseries analysis; because it did also seem like they wanted _us_ to their basic regression analysis as well...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.choice(df['Image Name'], size=(51,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[df['Image Name'].isin(X)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "ONS = \"Raw ONS Line and Pack\"\n",
    "\n",
    "for k in TO_NORMALIZE:\n",
    "    R = df_[ONS].corr(df_[k])\n",
    "    print(k, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[ONS].corr(df_['Dollar Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5989d0768d935c7ff7e4731f453a8814b618c97145c1a2ccb8e17767eb008288"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
